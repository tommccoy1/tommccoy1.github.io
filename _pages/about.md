---
permalink: /
title: 
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am an Assistant Professor in the [Department of Linguistics](https://ling.yale.edu/) at Yale University. I study computational linguistics using techniques from cognitive science, machine learning, and natural language processing. 

My research focuses on the computational principles that underlie human language. I am particularly interested in language learning and linguistic representations. On the side of learning, I investigate how people can acquire language from so little data and how we can replicate this ability in machines. On the side of representations, I investigate what types of machines can represent the structure of language and how they do it. Much of my research involves neural network language models, with an emphasis on connecting such systems to linguistics.

For a longer overview of my research, click [here](https://rtmccoy.com/research/). If you want an even more detailed discussion, you can read [this summary for a linguistics/cognitive science audience](https://rtmccoy.com/files/mccoy_ling_research_statement_10sept2023.pdf) or [this summary for a computer science audience](https://rtmccoy.com/files/mccoy_nlp_research_statement_10sept2023.pdf), or check out [my publications](https://rtmccoy.com/pubs/).


## Conversation topics

 Do you have a meeting scheduled with me but don't know what to talk about? See [this page](https://rtmccoy.com/topics/) for some topics that are often on my mind.


## Prospective PhD students, postdocs, and undergraduate researchers

I am currently considering postdoc applications for Fall 2025. See [here](https://rtmccoy.com/prospective_postdocs/) for more information.

I will also be considering PhD applicants for Fall 2025. See [here](https://rtmccoy.com/prospective_students_and_postdocs) for more information.

I am not accepting Master's students at this time.

If you are a current Yale undergraduate interested in research, feel free to email me to check if there are any research opportunities available. Unfortunately, I am unable to host undergraduate research assistants who are not current Yale students.

## Representative papers

- <b>R. Thomas McCoy</b> and Thomas L. Griffiths. Modeling rapid language learning by distilling Bayesian priors into artificial neural networks. <em>arXiv preprint arXiv 2305.14701</em>. [<a href="https://arxiv.org/pdf/2305.14701.pdf">pdf</a>]
- <b>R. Thomas McCoy</b>, Shunyu Yao, Dan Friedman, Matthew Hardy, and Thomas L. Griffiths. Embers of Autoregression: Understanding Large Language Models Through the Problem They are Trained to Solve. <em>Proceedings of the National Academy of Sciences</em>. [<a href="https://www.pnas.org/doi/pdf/10.1073/pnas.2322420121">pdf</a>] [<a href="https://rtmccoy.com/embers_shift_ciphers.html">demo</a>]
- **R. Thomas McCoy**, Jennifer Culbertson, Paul Smolensky, and GÃ©raldine Legendre. Infinite use of finite means? Evaluating the generalization of center embedding learned from an artificial grammar. <em>Proceedings of the 43rd Annual Conference of the Cognitive Science Society</em>. [<a href="https://psyarxiv.com/r8ct2">pdf</a>] 
- **R. Thomas McCoy**, Ellie Pavlick, and Tal Linzen. Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural Language Inference. *ACL 2019*. [<a href="https://www.aclweb.org/anthology/P19-1334.pdf">pdf</a>]  
- **R. Thomas McCoy**, Robert Frank, and Tal Linzen. Does syntax need to grow on trees? Sources of hierarchical inductive bias in sequence-to-sequence networks. *TACL*. [<a href="https://www.mitpressjournals.org/doi/pdf/10.1162/tacl_a_00304">pdf</a>] [<a href="http://rtmccoy.com/rnn_hierarchical_biases.html">website</a>]
- **R. Thomas McCoy**, Tal Linzen, Ewan Dunbar, and Paul Smolensky. RNNs implicitly implement Tensor Product Representations. *ICLR 2019*. [<a href="https://openreview.net/pdf?id=BJx0sjC5FX">pdf</a>] [<a href="https://tommccoy1.github.io/tpdn/tpr_demo.html">demo</a>]



